{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671aa557",
   "metadata": {},
   "source": [
    "# Sprint 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e40bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import CDP_0_SRC\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import logging\n",
    "from optuna.visualization import plot_optimization_history, plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a2f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularidad(G, partition, weight='weight'):\n",
    "    \"\"\"\n",
    "    Cálculo vectorizado y correcto de Q.\n",
    "    Q = Sum_c [ (Lc/m) - (dc/2m)^2 ]\n",
    "    Donde:\n",
    "    - Lc: Suma de pesos de enlaces DENTRO de la comunidad c\n",
    "    - dc: Suma de grados de los nodos en la comunidad c\n",
    "    \"\"\"\n",
    "    m = G.size(weight=weight)\n",
    "    if m == 0: return 0\n",
    "    \n",
    "    # 1. Calcular suma de grados por comunidad (dc)\n",
    "    community_degrees = {}\n",
    "    for node, deg in G.degree(weight=weight):\n",
    "        comm = partition.get(node)\n",
    "        if comm is not None:\n",
    "            community_degrees[comm] = community_degrees.get(comm, 0.0) + deg\n",
    "            \n",
    "    # 2. Calcular suma de pesos internos por comunidad (Lc)\n",
    "    community_internal_weights = {}\n",
    "    # Iteramos solo aristas existentes (eficiente)\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        comm_u = partition.get(u)\n",
    "        comm_v = partition.get(v)\n",
    "        if comm_u is not None and comm_u == comm_v:\n",
    "            w = data.get(weight, 1.0)\n",
    "            community_internal_weights[comm_u] = community_internal_weights.get(comm_u, 0.0) + w\n",
    "            \n",
    "    # 3. Aplicar fórmula sumatoria (Mucho más rápido que iterar pares)\n",
    "    Q = 0.0\n",
    "    for comm in community_degrees:\n",
    "        Lc = community_internal_weights.get(comm, 0.0) # Pesos internos\n",
    "        dc = community_degrees[comm]                   # Grados totales\n",
    "        \n",
    "        term1 = Lc / m\n",
    "        term2 = (dc / (2 * m)) ** 2\n",
    "        \n",
    "        Q += term1 - term2\n",
    "        \n",
    "    return Q\n",
    "\n",
    "def generate_random_partition_with_all_nodes(G, k):\n",
    "    partition = {node: np.random.randint(1, k+1) for node in G.nodes()}\n",
    "    return partition\n",
    "\n",
    "def generate_random_move_neighbors(partition, k, num_vecinos):\n",
    "    \"\"\"\n",
    "    Genera una lista de 'num_vecinos' particiones ÚNICAS.\n",
    "    Evita devolver candidatos repetidos.\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "    nodes = list(partition.keys())\n",
    "    \n",
    "    # Con set evitamos duplicados\n",
    "    moves_set = set()\n",
    "    \n",
    "    max_possible_moves = len(nodes) * (k - 1)\n",
    "    target_count = min(num_vecinos, max_possible_moves)\n",
    "    \n",
    "    while len(moves_set) < target_count:\n",
    "        u = random.choice(nodes)\n",
    "        current_comm = partition[u]\n",
    "        \n",
    "        possible_communities = [c for c in range(1, k+1) if c != current_comm]\n",
    "        \n",
    "        if possible_communities:\n",
    "            new_comm = random.choice(possible_communities)\n",
    "            \n",
    "            moves_set.add((u, new_comm))\n",
    "\n",
    "    for u, new_comm in moves_set:\n",
    "        new_partition = partition.copy()\n",
    "        new_partition[u] = new_comm\n",
    "        neighbors.append(new_partition)\n",
    "        \n",
    "    return neighbors\n",
    "\n",
    "def random_search(G, k, evals):\n",
    "    \"\"\"\n",
    "    Algoritmo de búsqueda aleatoria (Baseline).\n",
    "    Genera soluciones al azar y se queda con la mejor.\n",
    "    \"\"\"\n",
    "    best_fit = -float('inf')\n",
    "    \n",
    "    # Bucle simple de evaluaciones\n",
    "    for _ in range(evals):\n",
    "        part = generate_random_partition_with_all_nodes(G, k)\n",
    "        fit = modularidad(G, part)\n",
    "        if fit > best_fit:\n",
    "            best_fit = fit\n",
    "            \n",
    "    return best_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df74102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastModularity:\n",
    "    def __init__(self, G):\n",
    "        self.G = G\n",
    "        self.m = G.size(weight='weight')\n",
    "        self.node_degrees = dict(G.degree(weight='weight'))\n",
    "        self.nodes = list(G.nodes())\n",
    "        self.two_m = 2 * self.m\n",
    "        \n",
    "    def calculate_from_scratch(self, partition):\n",
    "        \"\"\"Calcula Q inicial y prepara estructuras auxiliares.\"\"\"\n",
    "        # Estructura: Suma de grados de nodos en cada comunidad\n",
    "        self.comm_degrees = {} \n",
    "        # Estructura: Suma de pesos de enlaces internos en cada comunidad (opcional para delta, vital para Q)\n",
    "        # Para simplificar el delta, solo necesitamos comm_degrees y enlaces del nodo.\n",
    "        \n",
    "        for node, comm in partition.items():\n",
    "            deg = self.node_degrees[node]\n",
    "            self.comm_degrees[comm] = self.comm_degrees.get(comm, 0.0) + deg\n",
    "            \n",
    "        return modularidad(self.G, partition) # Usamos la función lenta una sola vez al inicio\n",
    "\n",
    "    def get_delta_Q(self, node, old_comm, new_comm, partition):\n",
    "        \"\"\"\n",
    "        Calcula variacion de modularidad al mover 'node' de 'old_comm' a 'new_comm'.\n",
    "        NO actualiza las estructuras, solo calcula.\n",
    "        \"\"\"\n",
    "        ki = self.node_degrees[node]\n",
    "        \n",
    "        # Enlaces del nodo 'node' hacia la comunidad antigua y nueva\n",
    "        k_i_in_old = 0.0\n",
    "        k_i_in_new = 0.0\n",
    "        \n",
    "        for neighbor in self.G.neighbors(node):\n",
    "            if neighbor == node: continue # Ignorar auto-bucles si los hay\n",
    "            nbr_comm = partition[neighbor]\n",
    "            w = self.G[node][neighbor].get('weight', 1.0)\n",
    "            \n",
    "            if nbr_comm == old_comm:\n",
    "                k_i_in_old += w\n",
    "            elif nbr_comm == new_comm:\n",
    "                k_i_in_new += w\n",
    "        \n",
    "        # Tot_c: Suma de grados en la comunidad\n",
    "        tot_old = self.comm_degrees.get(old_comm, 0.0)\n",
    "        tot_new = self.comm_degrees.get(new_comm, 0.0)\n",
    "        \n",
    "        # Fórmula Delta Q (simplificada de Newman):\n",
    "        # Ganancia al entrar a new - Pérdida al salir de old\n",
    "        \n",
    "        # Termino de salida (Remove):\n",
    "        # Se restan los enlaces internos que se pierden y se suma la penalización probabilística que se evita\n",
    "        # Nota: Al sacar el nodo, el tot_old bajaría, pero la fórmula delta usa el estado actual.\n",
    "        delta_remove = - (k_i_in_old / self.m) + (2 * ki * (tot_old - ki) / (self.two_m ** 2)) \n",
    "        \n",
    "        # Termino de entrada (Add):\n",
    "        # Se suman enlaces internos nuevos y se resta la penalización\n",
    "        delta_add = (k_i_in_new / self.m) - (2 * ki * tot_new / (self.two_m ** 2))\n",
    "        \n",
    "        return delta_add + delta_remove\n",
    "\n",
    "    def update_state(self, node, old_comm, new_comm):\n",
    "        \"\"\"Actualiza las estructuras internas tras un movimiento aceptado.\"\"\"\n",
    "        ki = self.node_degrees[node]\n",
    "        self.comm_degrees[old_comm] -= ki\n",
    "        self.comm_degrees[new_comm] = self.comm_degrees.get(new_comm, 0.0) + ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6f93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_constructive_greedy(G, k, fast_mod):\n",
    "    \"\"\"\n",
    "    Construye una partición asignando nodos uno a uno a la comunidad que más aporte.\n",
    "    Estocástico: El orden de los nodos es aleatorio.\n",
    "    \"\"\"\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes) # Estocasticidad 1: Orden aleatorio\n",
    "    \n",
    "    # Inicializar: k nodos aleatorios a k comunidades distintas para asegurar k comunidades\n",
    "    partition = {}\n",
    "    used_nodes = set()\n",
    "    \n",
    "    # Pre-asignar semillas\n",
    "    for i in range(1, k+1):\n",
    "        if i <= len(nodes):\n",
    "            node = nodes[i-1]\n",
    "            partition[node] = i\n",
    "            used_nodes.add(node)\n",
    "            # Actualizar estado de FastModularity (simulado)\n",
    "            fast_mod.comm_degrees[i] = fast_mod.comm_degrees.get(i, 0) + fast_mod.node_degrees[node]\n",
    "\n",
    "    # Asignar el resto\n",
    "    remaining_nodes = [n for n in nodes if n not in used_nodes]\n",
    "    \n",
    "    for node in remaining_nodes:\n",
    "        best_comm = random.randint(1, k)\n",
    "        best_delta = -float('inf')\n",
    "        \n",
    "        # Evaluar mover a cada comunidad existente\n",
    "        # Nota: Como el nodo no está en ninguna comunidad aún, \"old_comm\" es virtual (vacía)\n",
    "        # Usamos una lógica simplificada: donde gano más modularidad \"entrando\"\n",
    "        \n",
    "        for c in range(1, k+1):\n",
    "            # Calcular ganancia de entrar a c\n",
    "            k_i_in = 0\n",
    "            for nbr in G.neighbors(node):\n",
    "                if nbr in partition and partition[nbr] == c:\n",
    "                    k_i_in += G[node][nbr].get('weight', 1.0)\n",
    "            \n",
    "            tot_c = fast_mod.comm_degrees.get(c, 0.0)\n",
    "            ki = fast_mod.node_degrees[node]\n",
    "            \n",
    "            # Delta simplificado de inserción\n",
    "            delta = (k_i_in / fast_mod.m) - (ki * tot_c / (fast_mod.m * 2 * fast_mod.m)) # Aprox\n",
    "            \n",
    "            if delta > best_delta:\n",
    "                best_delta = delta\n",
    "                best_comm = c\n",
    "        \n",
    "        partition[node] = best_comm\n",
    "        fast_mod.comm_degrees[best_comm] = fast_mod.comm_degrees.get(best_comm, 0) + fast_mod.node_degrees[node]\n",
    "        \n",
    "    return partition, modularidad(G, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4ea22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_optimized(G, k, max_evals, initial_temp, alpha):\n",
    "    # Inicialización aleatoria\n",
    "    current_partition = generate_random_partition_with_all_nodes(G, k)\n",
    "    \n",
    "    # Inicializar FastModularity\n",
    "    fm = FastModularity(G)\n",
    "    current_fitness = fm.calculate_from_scratch(current_partition)\n",
    "    \n",
    "    best_partition = current_partition.copy()\n",
    "    best_fitness = current_fitness\n",
    "    \n",
    "    temp = initial_temp\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for _ in range(max_evals):\n",
    "        # Vecino: Mover 1 nodo\n",
    "        node = random.choice(nodes)\n",
    "        old_comm = current_partition[node]\n",
    "        possible = [c for c in range(1, k+1) if c != old_comm]\n",
    "        if not possible: continue\n",
    "        new_comm = random.choice(possible)\n",
    "        \n",
    "        # Calcular Delta Q eficientemente\n",
    "        delta = fm.get_delta_Q(node, old_comm, new_comm, current_partition)\n",
    "        \n",
    "        # Criterio de aceptación (Maximizar Q)\n",
    "        accept = False\n",
    "        if delta > 0:\n",
    "            accept = True\n",
    "        else:\n",
    "            try:\n",
    "                prob = math.exp(delta / temp)\n",
    "            except OverflowError:\n",
    "                prob = 0\n",
    "            if random.random() < prob:\n",
    "                accept = True\n",
    "        \n",
    "        if accept:\n",
    "            current_partition[node] = new_comm\n",
    "            current_fitness += delta\n",
    "            fm.update_state(node, old_comm, new_comm)\n",
    "            \n",
    "            if current_fitness > best_fitness:\n",
    "                best_fitness = current_fitness\n",
    "                best_partition = current_partition.copy()\n",
    "        \n",
    "        temp *= alpha\n",
    "        if temp < 1e-6: temp = initial_temp * 0.1 # Reheating simple\n",
    "            \n",
    "    return best_partition, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3ce5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_optimized(G, k, pop_size, max_evals, mutation_rate):\n",
    "    # Generaciones aproximadas\n",
    "    generations = max_evals // pop_size\n",
    "    \n",
    "    population = [generate_random_partition_with_all_nodes(G, k) for _ in range(pop_size)]\n",
    "    # Evaluar iniciales\n",
    "    fitnesses = [modularidad(G, p) for p in population]\n",
    "    \n",
    "    best_overall_fit = max(fitnesses)\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        new_population = []\n",
    "        \n",
    "        # Elitismo (Guardar el mejor)\n",
    "        idx_best = np.argmax(fitnesses)\n",
    "        new_population.append(population[idx_best].copy())\n",
    "        \n",
    "        while len(new_population) < pop_size:\n",
    "            # Torneo binario\n",
    "            def tournament():\n",
    "                i1, i2 = random.sample(range(pop_size), 2)\n",
    "                return population[i1] if fitnesses[i1] > fitnesses[i2] else population[i2]\n",
    "            \n",
    "            p1 = tournament()\n",
    "            p2 = tournament()\n",
    "            \n",
    "            # Cruce Uniforme\n",
    "            child = {}\n",
    "            # Heredar genes\n",
    "            for node in G.nodes():\n",
    "                child[node] = p1[node] if random.random() < 0.5 else p2[node]\n",
    "            \n",
    "            # Mutación\n",
    "            if random.random() < mutation_rate:\n",
    "                node_mut = random.choice(list(G.nodes()))\n",
    "                child[node_mut] = random.randint(1, k)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        population = new_population\n",
    "        # Recalcular fitness (Cuello de botella real del GA, difícil de optimizar incrementalmente sin mantener estado por individuo)\n",
    "        fitnesses = [modularidad(G, p) for p in population]\n",
    "        \n",
    "        current_best = max(fitnesses)\n",
    "        if current_best > best_overall_fit:\n",
    "            best_overall_fit = current_best\n",
    "            \n",
    "    return None, best_overall_fit # Retornamos solo fitness para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos y generando grafo...\n",
      "--- Calibrando SA para k=10 ---\n",
      "Mejores params SA: {'initial_temp': 0.32560098193455345, 'alpha': 0.9692087185879967} -> Fit: 0.1058\n",
      "--- Calibrando GA para k=10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2026-01-12 18:18:14,580] Trial 0 failed with parameters: {'mutation_rate': 0.3503443313378682} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\ikerg\\AppData\\Local\\Temp\\ipykernel_11096\\2968607307.py\", line 56, in objective\n",
      "    _, fitness = genetic_algorithm_optimized(\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        G,\n",
      "        ^^\n",
      "    ...<3 lines>...\n",
      "        mutation_rate=mutation_rate\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\ikerg\\AppData\\Local\\Temp\\ipykernel_11096\\2384170692.py\", line 42, in genetic_algorithm_optimized\n",
      "    fitnesses = [modularidad(G, p) for p in population]\n",
      "                 ~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\ikerg\\AppData\\Local\\Temp\\ipykernel_11096\\441104774.py\", line 24, in modularidad\n",
      "    comm_v = partition.get(v)\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-12 18:18:14,582] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     74\u001b[39m k_calibracion = \u001b[32m10\u001b[39m \n\u001b[32m     75\u001b[39m best_params_sa = calibrar_sa(G, k_calib=k_calibracion, n_trials=\u001b[32m20\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m best_params_ga = \u001b[43mcalibrar_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_calib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_calibracion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalibrar_sa_con_grafico\u001b[39m(G, k_calib, n_trials=\u001b[32m20\u001b[39m):\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Calibrando SA visualmente ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mcalibrar_ga\u001b[39m\u001b[34m(G, k_calib, n_trials)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 3. Optimizar\u001b[39;00m\n\u001b[32m     66\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMejores params GA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> Fit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study.best_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Iker MEGA\\Uni\\2025-26\\Primer Cuatrimestre\\HB\\Códigos\\cdp-proyecto\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mcalibrar_ga.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     53\u001b[39m mutation_rate = trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mmutation_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.01\u001b[39m, \u001b[32m0.5\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 2. Ejecutar algoritmo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m _, fitness = \u001b[43mgenetic_algorithm_optimized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_calib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Fijo para comparar peras con peras\u001b[39;49;00m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Menos evals para calibrar rápido\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmutation_rate\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fitness\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mgenetic_algorithm_optimized\u001b[39m\u001b[34m(G, k, pop_size, max_evals, mutation_rate)\u001b[39m\n\u001b[32m     40\u001b[39m population = new_population\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Recalcular fitness (Cuello de botella real del GA, difícil de optimizar incrementalmente sin mantener estado por individuo)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m fitnesses = [\u001b[43mmodularidad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m     44\u001b[39m current_best = \u001b[38;5;28mmax\u001b[39m(fitnesses)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_best > best_overall_fit:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mmodularidad\u001b[39m\u001b[34m(G, partition, weight)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u, v, data \u001b[38;5;129;01min\u001b[39;00m G.edges(data=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     23\u001b[39m     comm_u = partition.get(u)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     comm_v = \u001b[43mpartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m comm_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m comm_u == comm_v:\n\u001b[32m     26\u001b[39m         w = data.get(weight, \u001b[32m1.0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 0. CARGA DE DATOS ---\n",
    "print(\"Cargando datos y generando grafo...\")\n",
    "df = CDP_0_SRC.get_dataframe()\n",
    "G = CDP_0_SRC.crear_grafo(df)\n",
    "\n",
    "# --- 1. CONFIGURACIÓN OPTUNA (Dashboard + Visualización) ---\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def calibrar_sa(G, k_calib, n_trials=20):\n",
    "    \"\"\"\n",
    "    Calibra SA, guarda en BD para Dashboard y muestra gráficos.\n",
    "    \"\"\"\n",
    "    print(f\"--- Calibrando SA para k={k_calib} ---\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        # 1. Parámetros\n",
    "        init_temp = trial.suggest_float(\"initial_temp\", 0.1, 10.0)\n",
    "        alpha = trial.suggest_float(\"alpha\", 0.80, 0.9999)\n",
    "        \n",
    "        # 2. Ejecutar (versión rápida 2000 evals)\n",
    "        _, fitness = simulated_annealing_optimized(\n",
    "            G, k=k_calib, max_evals=2000, \n",
    "            initial_temp=init_temp, alpha=alpha\n",
    "        )\n",
    "        return fitness\n",
    "\n",
    "    # 3. Crear estudio CON ALMACENAMIENTO (necesario para Dashboard)\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=\"sqlite:///calibracion_cdp.db\",  # Archivo BD\n",
    "        study_name=\"calibracion_sa\",            # Nombre único\n",
    "        load_if_exists=True                     # Continuar si existe\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # 4. Visualización en Notebook\n",
    "    print(\"Generando gráficos interactivos de SA...\")\n",
    "    try:\n",
    "        fig1 = plot_optimization_history(study)\n",
    "        fig1.show()\n",
    "        fig2 = plot_slice(study)\n",
    "        fig2.show()\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudieron generar gráficos interactivos: {e}\")\n",
    "\n",
    "    print(f\"Mejores params SA: {study.best_params} -> Fit: {study.best_value:.4f}\")\n",
    "    return study.best_params\n",
    "\n",
    "def calibrar_ga(G, k_calib, n_trials=20):\n",
    "    \"\"\"\n",
    "    Calibra GA, guarda en BD para Dashboard.\n",
    "    \"\"\"\n",
    "    print(f\"--- Calibrando GA para k={k_calib} ---\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        mutation_rate = trial.suggest_float(\"mutation_rate\", 0.01, 0.5)\n",
    "        \n",
    "        _, fitness = genetic_algorithm_optimized(\n",
    "            G, k=k_calib, pop_size=30, max_evals=2000, \n",
    "            mutation_rate=mutation_rate\n",
    "        )\n",
    "        return fitness\n",
    "\n",
    "    # Crear estudio CON ALMACENAMIENTO\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=\"sqlite:///calibracion_cdp.db\",\n",
    "        study_name=\"calibracion_ga\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # Visualización simple GA\n",
    "    try:\n",
    "        fig = plot_optimization_history(study)\n",
    "        fig.show()\n",
    "    except: pass\n",
    "    \n",
    "    print(f\"Mejores params GA: {study.best_params} -> Fit: {study.best_value:.4f}\")\n",
    "    return study.best_params\n",
    "\n",
    "# --- 2. EJECUCIÓN DE CALIBRACIÓN ---\n",
    "# Usamos un k intermedio\n",
    "k_calibracion = 10 \n",
    "\n",
    "# Borrar estudios previos si quieres empezar de cero (opcional)\n",
    "# optuna.delete_study(study_name=\"calibracion_sa\", storage=\"sqlite:///calibracion_cdp.db\")\n",
    "# optuna.delete_study(study_name=\"calibracion_ga\", storage=\"sqlite:///calibracion_cdp.db\")\n",
    "\n",
    "print(\">>> INICIANDO CALIBRACIÓN <<<\")\n",
    "best_params_sa = calibrar_sa(G, k_calib=k_calibracion, n_trials=20)\n",
    "best_params_ga = calibrar_ga(G, k_calib=k_calibracion, n_trials=20)\n",
    "\n",
    "\n",
    "# --- 3. EXPERIMENTACIÓN FINAL ---\n",
    "k_values = [2, 5, 10, 20, 50, 100] \n",
    "n_reps = 5 \n",
    "max_evals = 100000 # 10^5 evals completo\n",
    "\n",
    "results_data = []\n",
    "\n",
    "print(\"\\n>>> INICIANDO EXPERIMENTO FINAL <<<\")\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"--- Ejecurando para K={k} ---\")\n",
    "    for rep in range(n_reps):\n",
    "        \n",
    "        # A. Random Search\n",
    "        start = time.time()\n",
    "        rs_fit = random_search(G, k, max_evals)\n",
    "        results_data.append({'Algorithm': 'Random Search', 'k': k, 'Fitness': rs_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # B. Constructive\n",
    "        start = time.time()\n",
    "        fm_const = FastModularity(G)\n",
    "        fm_const.calculate_from_scratch({n:1 for n in G.nodes()})\n",
    "        _, const_fit = randomized_constructive_greedy(G, k, fm_const)\n",
    "        results_data.append({'Algorithm': 'Constructive', 'k': k, 'Fitness': const_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # C. Simulated Annealing (CALIBRADO)\n",
    "        start = time.time()\n",
    "        _, sa_fit = simulated_annealing_optimized(\n",
    "            G, k, max_evals, \n",
    "            initial_temp=best_params_sa[\"initial_temp\"], \n",
    "            alpha=best_params_sa[\"alpha\"]\n",
    "        )\n",
    "        results_data.append({'Algorithm': 'SA', 'k': k, 'Fitness': sa_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # D. Genetic Algorithm (CALIBRADO)\n",
    "        start = time.time()\n",
    "        _, ga_fit = genetic_algorithm_optimized(\n",
    "            G, k, \n",
    "            pop_size=50, \n",
    "            max_evals=max_evals, \n",
    "            mutation_rate=best_params_ga[\"mutation_rate\"]\n",
    "        )\n",
    "        results_data.append({'Algorithm': 'GA', 'k': k, 'Fitness': ga_fit, 'Time': time.time()-start})\n",
    "\n",
    "# --- 4. VISUALIZACIÓN FINAL ---\n",
    "df_res = pd.DataFrame(results_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_res, x='k', y='Fitness', hue='Algorithm', marker='o')\n",
    "plt.title('Comparación de Algoritmos (Modularidad vs K)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_res, x='Algorithm', y='Fitness')\n",
    "plt.title('Distribución de Fitness por Algoritmo')\n",
    "plt.show()\n",
    "\n",
    "# Para ver resultados:\n",
    "# 1- Instalar optuna-dashboard (py -m pip install optuna-dashboard)\n",
    "# 2- Ejecutar código del notebook\n",
    "# 3- Escribir [optuna-dashboard sqlite:///calibracion_cdp.db] en la terminal\n",
    "# 4- Abrir el localhost que marque y ver resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
