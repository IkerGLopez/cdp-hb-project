{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671aa557",
   "metadata": {},
   "source": [
    "# Sprint 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6e40bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import CDP_0_SRC\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a2f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularidad(G, partition, weight='weight'):\n",
    "    \"\"\"\n",
    "    Cálculo vectorizado y correcto de Q.\n",
    "    Q = Sum_c [ (Lc/m) - (dc/2m)^2 ]\n",
    "    Donde:\n",
    "    - Lc: Suma de pesos de enlaces DENTRO de la comunidad c\n",
    "    - dc: Suma de grados de los nodos en la comunidad c\n",
    "    \"\"\"\n",
    "    m = G.size(weight=weight)\n",
    "    if m == 0: return 0\n",
    "    \n",
    "    # 1. Calcular suma de grados por comunidad (dc)\n",
    "    community_degrees = {}\n",
    "    for node, deg in G.degree(weight=weight):\n",
    "        comm = partition.get(node)\n",
    "        if comm is not None:\n",
    "            community_degrees[comm] = community_degrees.get(comm, 0.0) + deg\n",
    "            \n",
    "    # 2. Calcular suma de pesos internos por comunidad (Lc)\n",
    "    community_internal_weights = {}\n",
    "    # Iteramos solo aristas existentes (eficiente)\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        comm_u = partition.get(u)\n",
    "        comm_v = partition.get(v)\n",
    "        if comm_u is not None and comm_u == comm_v:\n",
    "            w = data.get(weight, 1.0)\n",
    "            community_internal_weights[comm_u] = community_internal_weights.get(comm_u, 0.0) + w\n",
    "            \n",
    "    # 3. Aplicar fórmula sumatoria (Mucho más rápido que iterar pares)\n",
    "    Q = 0.0\n",
    "    for comm in community_degrees:\n",
    "        Lc = community_internal_weights.get(comm, 0.0) # Pesos internos\n",
    "        dc = community_degrees[comm]                   # Grados totales\n",
    "        \n",
    "        term1 = Lc / m\n",
    "        term2 = (dc / (2 * m)) ** 2\n",
    "        \n",
    "        Q += term1 - term2\n",
    "        \n",
    "    return Q\n",
    "\n",
    "def generate_random_partition_with_all_nodes(G, k):\n",
    "    partition = {node: np.random.randint(1, k+1) for node in G.nodes()}\n",
    "    return partition\n",
    "\n",
    "def generate_random_move_neighbors(partition, k, num_vecinos):\n",
    "    \"\"\"\n",
    "    Genera una lista de 'num_vecinos' particiones ÚNICAS.\n",
    "    Evita devolver candidatos repetidos.\n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "    nodes = list(partition.keys())\n",
    "    \n",
    "    # Con set evitamos duplicados\n",
    "    moves_set = set()\n",
    "    \n",
    "    max_possible_moves = len(nodes) * (k - 1)\n",
    "    target_count = min(num_vecinos, max_possible_moves)\n",
    "    \n",
    "    while len(moves_set) < target_count:\n",
    "        u = random.choice(nodes)\n",
    "        current_comm = partition[u]\n",
    "        \n",
    "        possible_communities = [c for c in range(1, k+1) if c != current_comm]\n",
    "        \n",
    "        if possible_communities:\n",
    "            new_comm = random.choice(possible_communities)\n",
    "            \n",
    "            moves_set.add((u, new_comm))\n",
    "\n",
    "    for u, new_comm in moves_set:\n",
    "        new_partition = partition.copy()\n",
    "        new_partition[u] = new_comm\n",
    "        neighbors.append(new_partition)\n",
    "        \n",
    "    return neighbors\n",
    "\n",
    "def random_search(G, k, evals):\n",
    "    \"\"\"\n",
    "    Algoritmo de búsqueda aleatoria (Baseline).\n",
    "    Genera soluciones al azar y se queda con la mejor.\n",
    "    \"\"\"\n",
    "    best_fit = -float('inf')\n",
    "    \n",
    "    # Bucle simple de evaluaciones\n",
    "    for _ in range(evals):\n",
    "        part = generate_random_partition_with_all_nodes(G, k)\n",
    "        fit = modularidad(G, part)\n",
    "        if fit > best_fit:\n",
    "            best_fit = fit\n",
    "            \n",
    "    return best_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df74102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastModularity:\n",
    "    def __init__(self, G):\n",
    "        self.G = G\n",
    "        self.m = G.size(weight='weight')\n",
    "        self.node_degrees = dict(G.degree(weight='weight'))\n",
    "        self.nodes = list(G.nodes())\n",
    "        self.two_m = 2 * self.m\n",
    "        \n",
    "    def calculate_from_scratch(self, partition):\n",
    "        \"\"\"Calcula Q inicial y prepara estructuras auxiliares.\"\"\"\n",
    "        # Estructura: Suma de grados de nodos en cada comunidad\n",
    "        self.comm_degrees = {} \n",
    "        # Estructura: Suma de pesos de enlaces internos en cada comunidad (opcional para delta, vital para Q)\n",
    "        # Para simplificar el delta, solo necesitamos comm_degrees y enlaces del nodo.\n",
    "        \n",
    "        for node, comm in partition.items():\n",
    "            deg = self.node_degrees[node]\n",
    "            self.comm_degrees[comm] = self.comm_degrees.get(comm, 0.0) + deg\n",
    "            \n",
    "        return modularidad(self.G, partition) # Usamos la función lenta una sola vez al inicio\n",
    "\n",
    "    def get_delta_Q(self, node, old_comm, new_comm, partition):\n",
    "        \"\"\"\n",
    "        Calcula variacion de modularidad al mover 'node' de 'old_comm' a 'new_comm'.\n",
    "        NO actualiza las estructuras, solo calcula.\n",
    "        \"\"\"\n",
    "        ki = self.node_degrees[node]\n",
    "        \n",
    "        # Enlaces del nodo 'node' hacia la comunidad antigua y nueva\n",
    "        k_i_in_old = 0.0\n",
    "        k_i_in_new = 0.0\n",
    "        \n",
    "        for neighbor in self.G.neighbors(node):\n",
    "            if neighbor == node: continue # Ignorar auto-bucles si los hay\n",
    "            nbr_comm = partition[neighbor]\n",
    "            w = self.G[node][neighbor].get('weight', 1.0)\n",
    "            \n",
    "            if nbr_comm == old_comm:\n",
    "                k_i_in_old += w\n",
    "            elif nbr_comm == new_comm:\n",
    "                k_i_in_new += w\n",
    "        \n",
    "        # Tot_c: Suma de grados en la comunidad\n",
    "        tot_old = self.comm_degrees.get(old_comm, 0.0)\n",
    "        tot_new = self.comm_degrees.get(new_comm, 0.0)\n",
    "        \n",
    "        # Fórmula Delta Q (simplificada de Newman):\n",
    "        # Ganancia al entrar a new - Pérdida al salir de old\n",
    "        \n",
    "        # Termino de salida (Remove):\n",
    "        # Se restan los enlaces internos que se pierden y se suma la penalización probabilística que se evita\n",
    "        # Nota: Al sacar el nodo, el tot_old bajaría, pero la fórmula delta usa el estado actual.\n",
    "        delta_remove = - (k_i_in_old / self.m) + (2 * ki * (tot_old - ki) / (self.two_m ** 2)) \n",
    "        \n",
    "        # Termino de entrada (Add):\n",
    "        # Se suman enlaces internos nuevos y se resta la penalización\n",
    "        delta_add = (k_i_in_new / self.m) - (2 * ki * tot_new / (self.two_m ** 2))\n",
    "        \n",
    "        return delta_add + delta_remove\n",
    "\n",
    "    def update_state(self, node, old_comm, new_comm):\n",
    "        \"\"\"Actualiza las estructuras internas tras un movimiento aceptado.\"\"\"\n",
    "        ki = self.node_degrees[node]\n",
    "        self.comm_degrees[old_comm] -= ki\n",
    "        self.comm_degrees[new_comm] = self.comm_degrees.get(new_comm, 0.0) + ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d6f93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_constructive_greedy(G, k, fast_mod):\n",
    "    \"\"\"\n",
    "    Construye una partición asignando nodos uno a uno a la comunidad que más aporte.\n",
    "    Estocástico: El orden de los nodos es aleatorio.\n",
    "    \"\"\"\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes) # Estocasticidad 1: Orden aleatorio\n",
    "    \n",
    "    # Inicializar: k nodos aleatorios a k comunidades distintas para asegurar k comunidades\n",
    "    partition = {}\n",
    "    used_nodes = set()\n",
    "    \n",
    "    # Pre-asignar semillas\n",
    "    for i in range(1, k+1):\n",
    "        if i <= len(nodes):\n",
    "            node = nodes[i-1]\n",
    "            partition[node] = i\n",
    "            used_nodes.add(node)\n",
    "            # Actualizar estado de FastModularity (simulado)\n",
    "            fast_mod.comm_degrees[i] = fast_mod.comm_degrees.get(i, 0) + fast_mod.node_degrees[node]\n",
    "\n",
    "    # Asignar el resto\n",
    "    remaining_nodes = [n for n in nodes if n not in used_nodes]\n",
    "    \n",
    "    for node in remaining_nodes:\n",
    "        best_comm = random.randint(1, k)\n",
    "        best_delta = -float('inf')\n",
    "        \n",
    "        # Evaluar mover a cada comunidad existente\n",
    "        # Nota: Como el nodo no está en ninguna comunidad aún, \"old_comm\" es virtual (vacía)\n",
    "        # Usamos una lógica simplificada: donde gano más modularidad \"entrando\"\n",
    "        \n",
    "        for c in range(1, k+1):\n",
    "            # Calcular ganancia de entrar a c\n",
    "            k_i_in = 0\n",
    "            for nbr in G.neighbors(node):\n",
    "                if nbr in partition and partition[nbr] == c:\n",
    "                    k_i_in += G[node][nbr].get('weight', 1.0)\n",
    "            \n",
    "            tot_c = fast_mod.comm_degrees.get(c, 0.0)\n",
    "            ki = fast_mod.node_degrees[node]\n",
    "            \n",
    "            # Delta simplificado de inserción\n",
    "            delta = (k_i_in / fast_mod.m) - (ki * tot_c / (fast_mod.m * 2 * fast_mod.m)) # Aprox\n",
    "            \n",
    "            if delta > best_delta:\n",
    "                best_delta = delta\n",
    "                best_comm = c\n",
    "        \n",
    "        partition[node] = best_comm\n",
    "        fast_mod.comm_degrees[best_comm] = fast_mod.comm_degrees.get(best_comm, 0) + fast_mod.node_degrees[node]\n",
    "        \n",
    "    return partition, modularidad(G, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb4ea22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_optimized(G, k, max_evals, initial_temp, alpha):\n",
    "    # Inicialización aleatoria\n",
    "    current_partition = generate_random_partition_with_all_nodes(G, k)\n",
    "    \n",
    "    # Inicializar FastModularity\n",
    "    fm = FastModularity(G)\n",
    "    current_fitness = fm.calculate_from_scratch(current_partition)\n",
    "    \n",
    "    best_partition = current_partition.copy()\n",
    "    best_fitness = current_fitness\n",
    "    \n",
    "    temp = initial_temp\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for _ in range(max_evals):\n",
    "        # Vecino: Mover 1 nodo\n",
    "        node = random.choice(nodes)\n",
    "        old_comm = current_partition[node]\n",
    "        possible = [c for c in range(1, k+1) if c != old_comm]\n",
    "        if not possible: continue\n",
    "        new_comm = random.choice(possible)\n",
    "        \n",
    "        # Calcular Delta Q eficientemente\n",
    "        delta = fm.get_delta_Q(node, old_comm, new_comm, current_partition)\n",
    "        \n",
    "        # Criterio de aceptación (Maximizar Q)\n",
    "        accept = False\n",
    "        if delta > 0:\n",
    "            accept = True\n",
    "        else:\n",
    "            try:\n",
    "                prob = math.exp(delta / temp)\n",
    "            except OverflowError:\n",
    "                prob = 0\n",
    "            if random.random() < prob:\n",
    "                accept = True\n",
    "        \n",
    "        if accept:\n",
    "            current_partition[node] = new_comm\n",
    "            current_fitness += delta\n",
    "            fm.update_state(node, old_comm, new_comm)\n",
    "            \n",
    "            if current_fitness > best_fitness:\n",
    "                best_fitness = current_fitness\n",
    "                best_partition = current_partition.copy()\n",
    "        \n",
    "        temp *= alpha\n",
    "        if temp < 1e-6: temp = initial_temp * 0.1 # Reheating simple\n",
    "            \n",
    "    return best_partition, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac3ce5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_optimized(G, k, pop_size, max_evals, mutation_rate):\n",
    "    # Generaciones aproximadas\n",
    "    generations = max_evals // pop_size\n",
    "    \n",
    "    population = [generate_random_partition_with_all_nodes(G, k) for _ in range(pop_size)]\n",
    "    # Evaluar iniciales\n",
    "    fitnesses = [modularidad(G, p) for p in population]\n",
    "    \n",
    "    best_overall_fit = max(fitnesses)\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        new_population = []\n",
    "        \n",
    "        # Elitismo (Guardar el mejor)\n",
    "        idx_best = np.argmax(fitnesses)\n",
    "        new_population.append(population[idx_best].copy())\n",
    "        \n",
    "        while len(new_population) < pop_size:\n",
    "            # Torneo binario\n",
    "            def tournament():\n",
    "                i1, i2 = random.sample(range(pop_size), 2)\n",
    "                return population[i1] if fitnesses[i1] > fitnesses[i2] else population[i2]\n",
    "            \n",
    "            p1 = tournament()\n",
    "            p2 = tournament()\n",
    "            \n",
    "            # Cruce Uniforme\n",
    "            child = {}\n",
    "            # Heredar genes\n",
    "            for node in G.nodes():\n",
    "                child[node] = p1[node] if random.random() < 0.5 else p2[node]\n",
    "            \n",
    "            # Mutación\n",
    "            if random.random() < mutation_rate:\n",
    "                node_mut = random.choice(list(G.nodes()))\n",
    "                child[node_mut] = random.randint(1, k)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        population = new_population\n",
    "        # Recalcular fitness (Cuello de botella real del GA, difícil de optimizar incrementalmente sin mantener estado por individuo)\n",
    "        fitnesses = [modularidad(G, p) for p in population]\n",
    "        \n",
    "        current_best = max(fitnesses)\n",
    "        if current_best > best_overall_fit:\n",
    "            best_overall_fit = current_best\n",
    "            \n",
    "    return None, best_overall_fit # Retornamos solo fitness para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c849359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrando parámetros...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModuleSpec' object has no attribute 'get_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m n_reps = \u001b[32m5\u001b[39m \u001b[38;5;66;03m# Solicitado [cite: 149]\u001b[39;00m\n\u001b[32m     11\u001b[39m max_evals = \u001b[32m100000\u001b[39m \u001b[38;5;66;03m# 10^5 \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43mCDP_0_SRC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dataframe\u001b[49m()\n\u001b[32m     14\u001b[39m G = CDP_0_SRC.crear_grafo(df)\n\u001b[32m     16\u001b[39m results_data = []\n",
      "\u001b[31mAttributeError\u001b[39m: 'ModuleSpec' object has no attribute 'get_dataframe'"
     ]
    }
   ],
   "source": [
    "# 1. CALIBRACIÓN (Ejemplo rápido para SA)\n",
    "# Se debería hacer Grid Search formal, aquí un ejemplo simple\n",
    "print(\"Calibrando parámetros...\")\n",
    "best_alpha = 0.99\n",
    "best_temp = 1.0\n",
    "# (Aquí iría tu código de Grid Search con Optuna o bucles anidados si quieres nota extra)\n",
    "\n",
    "# 2. EXPERIMENTACIÓN\n",
    "k_values = [2, 5, 10, 20, 50, 100] # Rango solicitado [cite: 148]\n",
    "n_reps = 5 # Solicitado [cite: 149]\n",
    "max_evals = 100000 # 10^5 \n",
    "\n",
    "df = CDP_0_SRC.get_dataframe()\n",
    "G = CDP_0_SRC.crear_grafo(df)\n",
    "\n",
    "results_data = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"--- Ejecurando para K={k} ---\")\n",
    "    for rep in range(n_reps):\n",
    "        \n",
    "        # A. Random Search (Baseline) [cite: 152]\n",
    "        start = time.time()\n",
    "        rs_fit = random_search(G, k, max_evals)\n",
    "        results_data.append({'Algorithm': 'Random Search', 'k': k, 'Fitness': rs_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # B. Constructive (Greedy Estocástico)\n",
    "        start = time.time()\n",
    "        # El constructivo es rápido, hacemos una sola pasada o varias pequeñas\n",
    "        fm_const = FastModularity(G)\n",
    "        fm_const.calculate_from_scratch({n:1 for n in G.nodes()}) # Init dummy\n",
    "        _, const_fit = randomized_constructive_greedy(G, k, fm_const)\n",
    "        results_data.append({'Algorithm': 'Constructive', 'k': k, 'Fitness': const_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # C. Simulated Annealing\n",
    "        start = time.time()\n",
    "        _, sa_fit = simulated_annealing_optimized(G, k, max_evals, initial_temp=1.0, alpha=0.95)\n",
    "        results_data.append({'Algorithm': 'SA', 'k': k, 'Fitness': sa_fit, 'Time': time.time()-start})\n",
    "        \n",
    "        # D. Genetic Algorithm\n",
    "        start = time.time()\n",
    "        # Ajustamos pop_size para que pop * gen = max_evals\n",
    "        _, ga_fit = genetic_algorithm_optimized(G, k, pop_size=50, max_evals=max_evals, mutation_rate=0.1)\n",
    "        results_data.append({'Algorithm': 'GA', 'k': k, 'Fitness': ga_fit, 'Time': time.time()-start})\n",
    "\n",
    "# 3. VISUALIZACIÓN [cite: 153]\n",
    "df = pd.DataFrame(results_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x='k', y='Fitness', hue='Algorithm', marker='o')\n",
    "plt.title('Comparación de Algoritmos (Modularidad vs K)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='Algorithm', y='Fitness')\n",
    "plt.title('Distribución de Fitness por Algoritmo')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
